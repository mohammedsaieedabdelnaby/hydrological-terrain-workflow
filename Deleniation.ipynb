{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d55c0-b956-4651-a064-6b2ca0c10aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Point\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import LineString\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840d641-2e2c-42f8-a9c3-49bcbc4eda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install whitebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2f930-63b7-427d-b9dd-8d7addf68465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from whitebox import WhiteboxTools\n",
    "wbt = WhiteboxTools()\n",
    "wbt.help()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d71f9f-3cb0-4ef7-b44e-924cfb631f3d",
   "metadata": {},
   "source": [
    "# TERRIAN ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19c699a-7e28-46b1-b83f-3aa6caa949e0",
   "metadata": {},
   "source": [
    "## FILL DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b0c8a-e31f-4144-8faf-4ccea705c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.fill_depressions(\n",
    "    dem=r\"file_path\\output_AW3D30.tif\", \n",
    "    output=r\"file_path\\Fill.tif\", \n",
    "    fix_flats=True, \n",
    "    flat_increment=None, \n",
    "    max_depth=None, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc834f-04fd-48c7-8c92-947adff04ca7",
   "metadata": {},
   "source": [
    "## FLOW DIRECTION 'D8_METHOD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92857603-a72d-4a5a-a78c-e21cd878bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.d8_pointer(\n",
    "    dem=r\"file_path\\Fill.tif\", \n",
    "    output=r\"file_path\\D8.tif\", \n",
    "    esri_pntr=False, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feaf8c5-5bf4-4772-b755-04943d52533e",
   "metadata": {},
   "source": [
    "## FLOW ACCUMULARION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3913795c-7c27-4dea-b40c-eb091ed94435",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.d8_flow_accumulation(\n",
    "    i=r\"file_path\\D8.tif\", \n",
    "    output=r\"file_path\\Fac.tif\", \n",
    "    out_type=\"cells\", \n",
    "    log=False, \n",
    "    clip=False, \n",
    "    pntr=True, \n",
    "    esri_pntr=False, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8368e-bff6-460f-9a34-b0c2ba385e7b",
   "metadata": {},
   "source": [
    "## STREAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bcd6e5-bf53-4240-be8a-9e92cc569eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.extract_streams(\n",
    "     flow_accum=r\"file_path\\Fac.tif\", \n",
    "    output=r\"file_path\\Str.tif\", \n",
    "    threshold=16000, # NO OF CELLS\n",
    "    zero_background=False \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0deba49-bee7-446f-9108-da041ce1c8b4",
   "metadata": {},
   "source": [
    "## Sanps 'opptional or U can Use the QGIS GUI'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eba2e4-3ddf-429a-8287-a718fd6a88aa",
   "metadata": {},
   "source": [
    "### Snap Pour Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0692d-0563-4ce3-97ed-a993a2531649",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.snap_pour_points(\n",
    "    pour_pts=r\"file_path\\Snap.shp\", \n",
    "    flow_accum=r\"file_path\\Fac.tif\", \n",
    "    output=r\"file_path\\SPP.shp\", \n",
    "    snap_dist=100, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1cbf45-fff9-4024-9de2-a9bf30645147",
   "metadata": {},
   "source": [
    "### jsnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdb562-2772-4c61-a3b1-70cdeadfa4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.jenson_snap_pour_points(\n",
    "    pour_pts=r\"file_path\\SNAP.shp\", \n",
    "    streams=r\"file_path\\Str.tif\", \n",
    "    output=r\"file_path\\Jsnap\", \n",
    "    snap_dist=200, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6e755-d456-4226-acab-30cbd0dd5ec1",
   "metadata": {},
   "source": [
    "## Watersheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399204c5-0b5a-4ee4-93e1-2ec9c705c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.watershed(\n",
    "     d8_pntr=r'file_path\\d8.tif', \n",
    "    pour_pts=r'file_path\\SNAP.shp', \n",
    "    output=r'file_path\\WS.TIFF',  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f418e9-5189-4ca1-90b6-c3cd8a43a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.raster_to_vector_polygons(\n",
    "    i=r\"file_path\\WS.tifF\", \n",
    "    output=r\"file_path\\WS.shp\", \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad80a1-6a3b-4d26-af7d-20d741bc8bb0",
   "metadata": {},
   "source": [
    "## Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb6bf3-9862-406f-816d-1fc0fe2c56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.raster_streams_to_vector(\n",
    "    streams=r'file_path\\Str.tif', \n",
    "    d8_pntr=r'file_path\\D8.tif', \n",
    "    output=r'file_path\\streams', \n",
    "    esri_pntr=False, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86475d-3dc0-4eec-bae3-0159a9487d44",
   "metadata": {},
   "source": [
    "## LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032934ab-058f-4f4b-94f9-6a5fb855ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.longest_flowpath(\n",
    "    dem=r\"file_path\\Fill.tif\", \n",
    "    basins=r\"file_path\\WS.tiff\", \n",
    "    output=r\"file_path\\LFP.shp\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7cfe5b-d3e4-46ed-9c2a-0e5d8f371687",
   "metadata": {},
   "source": [
    "# LFP PARAMETERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38580b-fa6f-4d31-b1e3-d27f2a7460e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "# -------------------------\n",
    "shapefile_path\\ = \"LFP.shp\"\n",
    "dem_path = \"PRO.tif\"\n",
    "ID_FIELD = \"FID\"      # ðŸ”´ CHANGE THIS to your existing ID field name\n",
    "output_gpkg = \"LFP_with_metrics.gpkg\"\n",
    "\n",
    "# -------------------------\n",
    "# LOAD DATA\n",
    "# -------------------------\n",
    "lines = gpd.read_file(shapefile_path\\)\n",
    "\n",
    "dem = rasterio.open(dem_path)\n",
    "dem_array = dem.read(1)\n",
    "dem_transform = dem.transform\n",
    "dem_nrows, dem_ncols = dem_array.shape\n",
    "\n",
    "# -------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# -------------------------\n",
    "def coords_to_index(xs, ys, transform):\n",
    "    \"\"\"Convert x, y coordinates to DEM row/col indices (vectorized).\"\"\"\n",
    "    cols = ((xs - transform.c) / transform.a).astype(int)\n",
    "    rows = ((ys - transform.f) / transform.e).astype(int)\n",
    "\n",
    "    rows = np.clip(rows, 0, dem_nrows - 1)\n",
    "    cols = np.clip(cols, 0, dem_ncols - 1)\n",
    "    return rows, cols\n",
    "\n",
    "def get_line_elevations(line_geom, dem_array, transform):\n",
    "    \"\"\"Extract elevations at line vertices.\"\"\"\n",
    "    coords = np.array(line_geom.coords)\n",
    "    xs, ys = coords[:, 0], coords[:, 1]\n",
    "    rows, cols = coords_to_index(xs, ys, transform)\n",
    "    elevations = dem_array[rows, cols]\n",
    "    return elevations[~np.isnan(elevations)]\n",
    "\n",
    "def compute_tc(Lseg, S):\n",
    "    \"\"\"Time of concentration formula.\"\"\"\n",
    "    if Lseg <= 0 or S <= 0:\n",
    "        return np.nan\n",
    "    return 0.0195 * (Lseg ** 0.77) * (S ** -0.385)\n",
    "\n",
    "def compute_metrics(row):\n",
    "    geom = row.geometry\n",
    "    elevations = get_line_elevations(geom, dem_array, dem_transform)\n",
    "\n",
    "    if len(elevations) == 0:\n",
    "        return None\n",
    "\n",
    "    # -------------------------\n",
    "    # BASIC METRICS\n",
    "    # -------------------------\n",
    "    L_total = geom.length\n",
    "    elev_us = elevations[0]\n",
    "    elev_ds = elevations[-1]\n",
    "    elev_10 = np.percentile(elevations, 10)\n",
    "    elev_85 = np.percentile(elevations, 85)\n",
    "\n",
    "    # -------------------------\n",
    "    # SEGMENT LENGTHS\n",
    "    # -------------------------\n",
    "    L1 = 0.15 * L_total\n",
    "    L2 = 0.70 * L_total\n",
    "    L3 = 0.15 * L_total\n",
    "\n",
    "    # -------------------------\n",
    "    # SLOPES\n",
    "    # -------------------------\n",
    "    slope1 = (elev_us - elev_85) / L1 if L1 > 0 else np.nan\n",
    "    slope2 = (elev_85 - elev_10) / L2 if L2 > 0 else np.nan\n",
    "    slope3 = (elev_10 - elev_ds) / L3 if L3 > 0 else np.nan\n",
    "\n",
    "    # -------------------------\n",
    "    # TIME OF CONCENTRATION\n",
    "    # -------------------------\n",
    "    Tc1 = compute_tc(L1, slope1)\n",
    "    Tc2 = compute_tc(L2, slope2)\n",
    "    Tc3 = compute_tc(L3, slope3)\n",
    "\n",
    "    return {\n",
    "        ID_FIELD: row[ID_FIELD],\n",
    "        \"length_m\": L_total,\n",
    "        \"elev_up\": elev_us,\n",
    "        \"elev_down\": elev_ds,\n",
    "        \"elev_10\": elev_10,\n",
    "        \"elev_85\": elev_85,\n",
    "        \"slope_u15\": slope1,\n",
    "        \"slope_m70\": slope2,\n",
    "        \"slope_l15\": slope3,\n",
    "        \"Tc_u15_min\": Tc1,\n",
    "        \"Tc_m70_min\": Tc2,\n",
    "        \"Tc_l15_min\": Tc3,\n",
    "        \"Tc_total_min\": Tc1 + Tc2 + Tc3\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# PROCESS ALL LINES\n",
    "# -------------------------\n",
    "results = []\n",
    "\n",
    "print(f\"Processing {len(lines)} flow paths...\")\n",
    "for _, row in tqdm(lines.iterrows(), total=len(lines), desc=\"Flow paths\"):\n",
    "    metrics = compute_metrics(row)\n",
    "    if metrics is not None:\n",
    "        results.append(metrics)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# -------------------------\n",
    "# ENSURE ID TYPE MATCH\n",
    "# -------------------------\n",
    "lines[ID_FIELD] = lines[ID_FIELD].astype(df[ID_FIELD].dtype)\n",
    "\n",
    "# -------------------------\n",
    "# JOIN RESULTS BACK\n",
    "# -------------------------\n",
    "lines_joined = lines.merge(\n",
    "    df,\n",
    "    on=ID_FIELD,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# SAVE OUTPUT (BEST FORMAT)\n",
    "# -------------------------\n",
    "lines_joined.to_file(\n",
    "    output_gpkg,\n",
    "    layer=\"flow_paths\",\n",
    "    driver=\"GPKG\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Processing complete\")\n",
    "print(f\"âœ… Output saved to: {output_gpkg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5113fd-0f54-414a-a42f-59ef0fea388b",
   "metadata": {},
   "source": [
    "# join by nearest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808f10a-e84f-4369-8b50-3ee6e892e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUTS\n",
    "# ----------------------------------\n",
    "watershed_fp = r\"file_path\\WS.shp\"\n",
    "\n",
    "lfp_gpkg = r\"file_path\\LFP_with_metrics.gpkg\"\n",
    "lfp_layer = \"flow_paths\"\n",
    "\n",
    "output_fp = r\"file_path\\watersheds.shp\"\n",
    "\n",
    "target_epsg = 32636   # UTM zone example\n",
    "\n",
    "# ----------------------------------\n",
    "# LOAD DATA\n",
    "# ----------------------------------\n",
    "watersheds = gpd.read_file(watershed_fp)\n",
    "flowpaths  = gpd.read_file(lfp_gpkg, layer=lfp_layer)\n",
    "\n",
    "print(\"âœ” Data loaded\")\n",
    "\n",
    "# ----------------------------------\n",
    "# CRS CHECK & REPROJECT\n",
    "# ----------------------------------\n",
    "if watersheds.crs is None or flowpaths.crs is None:\n",
    "    raise ValueError(\"âŒ One or both layers have no CRS\")\n",
    "\n",
    "watersheds = watersheds.to_crs(epsg=target_epsg)\n",
    "flowpaths  = flowpaths.to_crs(epsg=target_epsg)\n",
    "\n",
    "print(\"âœ” CRS aligned:\", watersheds.crs)\n",
    "\n",
    "# ----------------------------------\n",
    "# MANUAL ONE-TO-ONE NEAREST JOIN\n",
    "# ----------------------------------\n",
    "nearest_idx = []\n",
    "\n",
    "for ws in watersheds.geometry:\n",
    "    dists = flowpaths.geometry.distance(ws)\n",
    "    nearest_idx.append(dists.idxmin())\n",
    "\n",
    "nearest_flowpaths = flowpaths.loc[nearest_idx].reset_index(drop=True)\n",
    "\n",
    "# Distance column\n",
    "nearest_flowpaths[\"dist_to_ws_m\"] = [\n",
    "    flowpaths.loc[idx].geometry.distance(ws)\n",
    "    for idx, ws in zip(nearest_idx, watersheds.geometry)\n",
    "]\n",
    "\n",
    "# ----------------------------------\n",
    "# MERGE ATTRIBUTES\n",
    "# ----------------------------------\n",
    "flow_attrs = nearest_flowpaths.drop(columns=\"geometry\")\n",
    "\n",
    "watersheds = pd.concat(\n",
    "    [watersheds.reset_index(drop=True),\n",
    "     flow_attrs.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ----------------------------------\n",
    "# DELETE EXISTING SHAPEFILE (IF EXISTS)\n",
    "# ----------------------------------\n",
    "if os.path.exists(output_fp):\n",
    "    base = os.path.splitext(output_fp)[0]\n",
    "    for f in glob.glob(base + \".*\"):\n",
    "        os.remove(f)\n",
    "    print(\"âœ” Existing Shapefile removed\")\n",
    "\n",
    "# ----------------------------------\n",
    "# SAVE OUTPUT (UPDATED SHP)\n",
    "# ----------------------------------\n",
    "os.makedirs(os.path.dirname(output_fp), exist_ok=True)\n",
    "watersheds.to_file(output_fp)\n",
    "\n",
    "print(\"âœ” Output saved to:\", output_fp)\n",
    "print(\"âœ” All watersheds updated with exactly one nearest flow path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52eb619-5a27-482d-a621-64264cc89c2e",
   "metadata": {},
   "source": [
    "## Attributes And Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc1df7-e1ef-4163-8f19-e9d4953ad2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FILE (overwrite same shapefile)\n",
    "# ----------------------------------\n",
    "input_fp = r\"file_path\\watersheds.shp\"\n",
    "output_fp = input_fp  # overwrite original file\n",
    "excel_fp = r\"file_path\\watersheds_attributes.xlsx\"  # Excel export path\n",
    "\n",
    "# ----------------------------------\n",
    "# LOAD SHAPEFILE\n",
    "# ----------------------------------\n",
    "gdf = gpd.read_file(input_fp)\n",
    "print(\"âœ” Shapefile loaded:\", gdf.shape)\n",
    "\n",
    "# ----------------------------------\n",
    "# DROP COLUMNS 2 TO 7 AND LAST COLUMN (except geometry)\n",
    "# ----------------------------------\n",
    "geom_col = gdf.geometry.name\n",
    "cols = list(gdf.columns)\n",
    "\n",
    "# Drop columns 2 to 7 (index 1 to 6) if enough exist\n",
    "if len(cols) > 7:\n",
    "    drop_cols = cols[1:7]\n",
    "    gdf = gdf.drop(columns=drop_cols)\n",
    "\n",
    "# Drop last column if it's not geometry\n",
    "if gdf.columns[-1] != geom_col:\n",
    "    gdf = gdf.drop(columns=gdf.columns[-1])\n",
    "\n",
    "# ----------------------------------\n",
    "# ADD WATERSHED_NAME FIELD AFTER FID\n",
    "# ----------------------------------\n",
    "if 'FID' in gdf.columns:\n",
    "    fid_index = gdf.columns.get_loc('FID')\n",
    "else:\n",
    "    fid_index = 0\n",
    "\n",
    "n = len(gdf)\n",
    "watershed_names = [f\"Watershed_{i+1:02d}\" for i in range(n)]\n",
    "gdf.insert(fid_index + 1, 'Watershed_Name', watershed_names)\n",
    "\n",
    "# ----------------------------------\n",
    "# REORDER COLUMNS: FID â†’ Watershed_Name â†’ others â†’ geometry\n",
    "# ----------------------------------\n",
    "other_cols = [c for c in gdf.columns if c not in ['FID', 'Watershed_Name', geom_col]]\n",
    "gdf = gdf[['FID', 'Watershed_Name'] + other_cols + [geom_col]]\n",
    "print(\"âœ” Columns adjusted:\", gdf.columns.tolist())\n",
    "\n",
    "# ----------------------------------\n",
    "# ROUND NUMERIC COLUMNS TO 2 DECIMALS (skip certain columns)\n",
    "# ----------------------------------\n",
    "# Columns to exclude from rounding\n",
    "exclude_cols = ['FID', 'Watershed_Name',\"slope_u15\",\"slope_m70\",\"slope_l15\"]\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = gdf.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Keep only numeric columns not in exclude list\n",
    "cols_to_round = [col for col in numeric_cols if col not in exclude_cols]\n",
    "\n",
    "# Round them\n",
    "for col in cols_to_round:\n",
    "    gdf[col] = (gdf[col] * 100).round() / 100\n",
    "\n",
    "print(\"âœ” Numeric columns rounded to 2 decimals (excluded FID and Watershed_Name)\")\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# SAVE CLEANED SHAPEFILE (overwrite)\n",
    "# ----------------------------------\n",
    "gdf.to_file(output_fp)\n",
    "print(\"âœ” Shapefile updated:\", output_fp)\n",
    "\n",
    "# ----------------------------------\n",
    "# EXPORT ATTRIBUTE TABLE TO EXCEL (overwrite, remove last column)\n",
    "# ----------------------------------\n",
    "attr_table = gdf.drop(columns=\"geometry\")\n",
    "attr_table = attr_table.iloc[:, :-1]  # remove last column\n",
    "attr_table.to_excel(excel_fp, index=False)\n",
    "print(\"âœ” Attribute table exported to Excel (last column removed, file overwritten)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56e93d-71a9-4f99-b971-bd752f50d98d",
   "metadata": {},
   "source": [
    "## PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0ba22-71cc-4876-95da-9d24fc453fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whitebox_workflows import WbPalette\n",
    "\n",
    "palettes = [p for p in dir(WbPalette) if not p.startswith('_')]\n",
    "print(palettes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c6c7d-ff3c-4cf1-bfc4-71ba7f15bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the files\n",
    "dem = wbe.read_raster(r'file_path\\mexar.tif')\n",
    "streams = wbe.read_vector(r'file_path\\clipped_streams.shp')\n",
    "LFP = wbe.read_vector(r'file_path\\LFP.shp')\n",
    "watershed = wbe.read_vector(r'file_path\\WS.shp')\n",
    "outlet = wbe.read_vector(r'file_path\\outlet.shp')\n",
    "study_area = wbe.read_vector(r'file_path\\BASEMAP.shp')  # study area\n",
    "\n",
    "# Create hillshade from DEM\n",
    "hillshade = wbe.hillshade(dem)\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "# Show DEM\n",
    "ax = show(dem, ax=ax, title='MEXAR', cmap=WbPalette.BlueGreenYellow, clip_percent=0.0, skip=2, colorbar_kwargs={'label': 'Elevation (m)', 'location': \"right\", 'shrink': 0.5}, zorder=1)\n",
    "\n",
    "# Overlay hillshade\n",
    "ax = show(hillshade, ax=ax, cmap='grey', clip_percent=10.0, skip=2, alpha=0.15, zorder=2)\n",
    "\n",
    "# Overlay watershed\n",
    "ax = show(watershed, ax=ax, color=(1.0, 1.0, 1.0, 0.3), edgecolor=(0.3, 0.3, 0.3, 0.5), linewidth=1.0, label='watershed', zorder=3)\n",
    "\n",
    "# Overlay study area boundary\n",
    "ax = show(study_area, ax=ax, color='black', linewidth=.5, label='study area', zorder=4)\n",
    "\n",
    "#Overlay Streams \n",
    "\n",
    "ax = show(streams, ax=ax, color='dodgerblue', linewidth=0.75, label='streams', zorder=5)\n",
    "\n",
    "\n",
    "# Overlay longest flow path\n",
    "ax = show(LFP, ax=ax, color='red', linewidth=0.9, label='longest flowpath', zorder=5)\n",
    "\n",
    "# Overlay outlet points\n",
    "ax = show(outlet, ax=ax, marker='^', s=43, color=(1.0, 0.0, 0.0), linewidth=1.75, label='outlet', zorder=6)\n",
    "\n",
    "\n",
    "# Set axes limits to DEM extent\n",
    "ax.set_xlim([dem.configs.west, dem.configs.east])\n",
    "ax.set_ylim([dem.configs.south, dem.configs.north])\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# save the map\n",
    "fig.savefig(r'file_path\\MEXAR_map.png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Show the map\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
